{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6df33173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: Euclidean, SSE: 25434764681.941788, Iterations: 89, Accuracy: 0.6027602760276027\n",
      "Method: Cosine, SSE: 682.1275065419829, Iterations: 22, Accuracy: 0.6096609660966097\n",
      "Method: Jaccard, SSE: 3663.479751658251, Iterations: 25, Accuracy: 0.6135613561356136\n"
     ]
    }
   ],
   "source": [
    "#Q1,Q2,Q3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import euclidean as euclidean_dist, cosine as cosine_dist\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Redefined distance computation functions\n",
    "def calc_euclidean_dist(point_a, point_b):\n",
    "    return euclidean_dist(point_a, point_b)\n",
    "\n",
    "def calc_cosine_similarity(point_a, point_b):\n",
    "    return 1 - np.dot(point_a, point_b) / (np.linalg.norm(point_a) * np.linalg.norm(point_b))\n",
    "\n",
    "def calc_generalized_jaccard_similarity(point_a, point_b):\n",
    "    min_sum = np.minimum(point_a, point_b).sum()\n",
    "    max_sum = np.maximum(point_a, point_b).sum()\n",
    "    return 1 - min_sum / max_sum if max_sum != 0 else 0\n",
    "\n",
    "# Modified K-means algorithm\n",
    "def perform_kmeans(data_points, num_clusters, distance_function, max_iterations=500):\n",
    "    random_indices = np.random.choice(data_points.shape[0], num_clusters, replace=False)\n",
    "    cluster_centers = data_points[random_indices]\n",
    "    \n",
    "    for iter in range(max_iterations):\n",
    "        assigned_clusters = np.array([np.argmin([distance_function(dp, center) for center in cluster_centers]) for dp in data_points])\n",
    "        updated_centers = np.array([data_points[assigned_clusters == idx].mean(axis=0) for idx in range(num_clusters)])\n",
    "        \n",
    "        if np.all(cluster_centers == updated_centers):\n",
    "            break\n",
    "        cluster_centers = updated_centers\n",
    "        \n",
    "        _, distances = pairwise_distances_argmin_min(data_points, cluster_centers, metric=distance_function)\n",
    "        sum_squared_error = np.sum(distances ** 2)\n",
    "        if iter > 0 and sum_squared_error > prev_sse:\n",
    "            break\n",
    "        prev_sse = sum_squared_error\n",
    "    \n",
    "    return assigned_clusters, cluster_centers, sum_squared_error, iter\n",
    "\n",
    "# Load dataset\n",
    "# Replace these with your actual file paths or data loading logic\n",
    "data = pd.read_csv('data.csv').values\n",
    "labels = pd.read_csv('label.csv').values.ravel()\n",
    "\n",
    "# Determine number of unique clusters\n",
    "num_clusters = np.unique(labels).size\n",
    "\n",
    "def calculate_accuracy(clusters, true_labels):\n",
    "    cluster_labels = {}\n",
    "    for cluster in set(clusters):\n",
    "        # Find the most frequent label in each cluster\n",
    "        labels_in_cluster = true_labels[clusters == cluster]\n",
    "        most_common_label = np.bincount(labels_in_cluster).argmax()\n",
    "        cluster_labels[cluster] = most_common_label\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    correct_labels_count = sum(cluster_labels[cluster] == true_label for cluster, true_label in zip(clusters, true_labels))\n",
    "    accuracy = correct_labels_count / len(true_labels)\n",
    "    return accuracy\n",
    "\n",
    "# Execute K-means with each distance metric\n",
    "kmeans_results = {}\n",
    "for dist_func, func_name in [(calc_euclidean_dist, 'Euclidean'), (calc_cosine_similarity, 'Cosine'), (calc_generalized_jaccard_similarity, 'Jaccard')]:\n",
    "    clusters, centers, sse, iters = perform_kmeans(data, num_clusters, dist_func)\n",
    "    accuracy = calculate_accuracy(clusters, labels)\n",
    "    kmeans_results[func_name] = {\n",
    "        'Sum of Squared Errors': sse, \n",
    "        'Iterations Completed': iters,\n",
    "        'Accuracy': accuracy\n",
    "    }\n",
    "\n",
    "# Print formatted results with accuracy\n",
    "for method, result in kmeans_results.items():\n",
    "    print(f\"Method: {method}, SSE: {result['Sum of Squared Errors']}, Iterations: {result['Iterations Completed']}, Accuracy: {result['Accuracy']}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c18cbd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: Euclidean, SSE: 25318083736.17222, Iterations: 99, Accuracy: 0.58995899589959\n",
      "Method: Cosine, SSE: 692.1907174210952, Iterations: 56, Accuracy: 0.6109610961096109\n",
      "Method: Jaccard, SSE: 3678.396182256969, Iterations: 48, Accuracy: 0.6231623162316232\n"
     ]
    }
   ],
   "source": [
    "# Q4 - when there is no change in centroid position\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import euclidean as euclidean_dist, cosine as cosine_dist\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Redefined distance computation functions\n",
    "def calc_euclidean_dist(point_a, point_b):\n",
    "    return euclidean_dist(point_a, point_b)\n",
    "\n",
    "def calc_cosine_similarity(point_a, point_b):\n",
    "    return 1 - np.dot(point_a, point_b) / (np.linalg.norm(point_a) * np.linalg.norm(point_b))\n",
    "\n",
    "def calc_generalized_jaccard_similarity(point_a, point_b):\n",
    "    min_sum = np.minimum(point_a, point_b).sum()\n",
    "    max_sum = np.maximum(point_a, point_b).sum()\n",
    "    return 1 - min_sum / max_sum if max_sum != 0 else 0\n",
    "\n",
    "# Modified K-means algorithm\n",
    "def perform_kmeans(data_points, num_clusters, distance_function, max_iterations=100):\n",
    "    random_indices = np.random.choice(data_points.shape[0], num_clusters, replace=False)\n",
    "    cluster_centers = data_points[random_indices]\n",
    "    \n",
    "    for iter in range(max_iterations):\n",
    "        assigned_clusters = np.array([np.argmin([distance_function(dp, center) for center in cluster_centers]) for dp in data_points])\n",
    "        updated_centers = np.array([data_points[assigned_clusters == idx].mean(axis=0) for idx in range(num_clusters)])\n",
    "        \n",
    "        if np.all(cluster_centers == updated_centers):\n",
    "            break\n",
    "        cluster_centers = updated_centers\n",
    "        \n",
    "        _, distances = pairwise_distances_argmin_min(data_points, cluster_centers, metric=distance_function)\n",
    "        sum_squared_error = np.sum(distances ** 2)\n",
    "        #if iter > 0 and sum_squared_error > prev_sse:\n",
    "        #    break\n",
    "        prev_sse = sum_squared_error\n",
    "    \n",
    "    return assigned_clusters, cluster_centers, sum_squared_error, iter\n",
    "\n",
    "# Load dataset\n",
    "# Replace these with your actual file paths or data loading logic\n",
    "data = pd.read_csv('data.csv').values\n",
    "labels = pd.read_csv('label.csv').values.ravel()\n",
    "\n",
    "# Determine number of unique clusters\n",
    "num_clusters = np.unique(labels).size\n",
    "\n",
    "def calculate_accuracy(clusters, true_labels):\n",
    "    cluster_labels = {}\n",
    "    for cluster in set(clusters):\n",
    "        # Find the most frequent label in each cluster\n",
    "        labels_in_cluster = true_labels[clusters == cluster]\n",
    "        most_common_label = np.bincount(labels_in_cluster).argmax()\n",
    "        cluster_labels[cluster] = most_common_label\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    correct_labels_count = sum(cluster_labels[cluster] == true_label for cluster, true_label in zip(clusters, true_labels))\n",
    "    accuracy = correct_labels_count / len(true_labels)\n",
    "    return accuracy\n",
    "\n",
    "# Execute K-means with each distance metric\n",
    "kmeans_results = {}\n",
    "for dist_func, func_name in [(calc_euclidean_dist, 'Euclidean'), (calc_cosine_similarity, 'Cosine'), (calc_generalized_jaccard_similarity, 'Jaccard')]:\n",
    "    clusters, centers, sse, iters = perform_kmeans(data, num_clusters, dist_func)\n",
    "    accuracy = calculate_accuracy(clusters, labels)\n",
    "    kmeans_results[func_name] = {\n",
    "        'Sum of Squared Errors': sse, \n",
    "        'Iterations Completed': iters,\n",
    "        'Accuracy': accuracy\n",
    "    }\n",
    "\n",
    "# Print formatted results with accuracy\n",
    "for method, result in kmeans_results.items():\n",
    "    print(f\"Method: {method}, SSE: {result['Sum of Squared Errors']}, Iterations: {result['Iterations Completed']}, Accuracy: {result['Accuracy']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7690d186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: Euclidean, SSE: 25400077155.69669, Iterations: 99, Accuracy: 0.6004600460046005\n",
      "Method: Cosine, SSE: 687.3261854086236, Iterations: 17, Accuracy: 0.5552555255525553\n",
      "Method: Jaccard, SSE: 3658.673997765767, Iterations: 25, Accuracy: 0.5999599959995999\n"
     ]
    }
   ],
   "source": [
    "# Q4 - when the SSE value increases in the next iteration\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import euclidean as euclidean_dist, cosine as cosine_dist\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Redefined distance computation functions\n",
    "def calc_euclidean_dist(point_a, point_b):\n",
    "    return euclidean_dist(point_a, point_b)\n",
    "\n",
    "def calc_cosine_similarity(point_a, point_b):\n",
    "    return 1 - np.dot(point_a, point_b) / (np.linalg.norm(point_a) * np.linalg.norm(point_b))\n",
    "\n",
    "def calc_generalized_jaccard_similarity(point_a, point_b):\n",
    "    min_sum = np.minimum(point_a, point_b).sum()\n",
    "    max_sum = np.maximum(point_a, point_b).sum()\n",
    "    return 1 - min_sum / max_sum if max_sum != 0 else 0\n",
    "\n",
    "# Modified K-means algorithm\n",
    "def perform_kmeans(data_points, num_clusters, distance_function, max_iterations=100):\n",
    "    random_indices = np.random.choice(data_points.shape[0], num_clusters, replace=False)\n",
    "    cluster_centers = data_points[random_indices]\n",
    "    \n",
    "    for iter in range(max_iterations):\n",
    "        assigned_clusters = np.array([np.argmin([distance_function(dp, center) for center in cluster_centers]) for dp in data_points])\n",
    "        updated_centers = np.array([data_points[assigned_clusters == idx].mean(axis=0) for idx in range(num_clusters)])\n",
    "        \n",
    "        #if np.all(cluster_centers == updated_centers):\n",
    "        #    break\n",
    "        cluster_centers = updated_centers\n",
    "        \n",
    "        _, distances = pairwise_distances_argmin_min(data_points, cluster_centers, metric=distance_function)\n",
    "        sum_squared_error = np.sum(distances ** 2)\n",
    "        if iter > 0 and sum_squared_error > prev_sse:\n",
    "            break\n",
    "        prev_sse = sum_squared_error\n",
    "    \n",
    "    return assigned_clusters, cluster_centers, sum_squared_error, iter\n",
    "\n",
    "# Load dataset\n",
    "# Replace these with your actual file paths or data loading logic\n",
    "data = pd.read_csv('data.csv').values\n",
    "labels = pd.read_csv('label.csv').values.ravel()\n",
    "\n",
    "# Determine number of unique clusters\n",
    "num_clusters = np.unique(labels).size\n",
    "\n",
    "def calculate_accuracy(clusters, true_labels):\n",
    "    cluster_labels = {}\n",
    "    for cluster in set(clusters):\n",
    "        # Find the most frequent label in each cluster\n",
    "        labels_in_cluster = true_labels[clusters == cluster]\n",
    "        most_common_label = np.bincount(labels_in_cluster).argmax()\n",
    "        cluster_labels[cluster] = most_common_label\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    correct_labels_count = sum(cluster_labels[cluster] == true_label for cluster, true_label in zip(clusters, true_labels))\n",
    "    accuracy = correct_labels_count / len(true_labels)\n",
    "    return accuracy\n",
    "\n",
    "# Execute K-means with each distance metric\n",
    "kmeans_results = {}\n",
    "for dist_func, func_name in [(calc_euclidean_dist, 'Euclidean'), (calc_cosine_similarity, 'Cosine'), (calc_generalized_jaccard_similarity, 'Jaccard')]:\n",
    "    clusters, centers, sse, iters = perform_kmeans(data, num_clusters, dist_func)\n",
    "    accuracy = calculate_accuracy(clusters, labels)\n",
    "    kmeans_results[func_name] = {\n",
    "        'Sum of Squared Errors': sse, \n",
    "        'Iterations Completed': iters,\n",
    "        'Accuracy': accuracy\n",
    "    }\n",
    "\n",
    "# Print formatted results with accuracy\n",
    "for method, result in kmeans_results.items():\n",
    "    print(f\"Method: {method}, SSE: {result['Sum of Squared Errors']}, Iterations: {result['Iterations Completed']}, Accuracy: {result['Accuracy']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ffb53f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: Euclidean, SSE: 25436632644.588085, Iterations: 99, Accuracy: 0.6062606260626062\n",
      "Method: Cosine, SSE: 682.0748392570059, Iterations: 99, Accuracy: 0.6131613161316132\n",
      "Method: Jaccard, SSE: 3678.4366672960273, Iterations: 99, Accuracy: 0.6230623062306231\n"
     ]
    }
   ],
   "source": [
    "# Q4 - when the maximum preset value (e.g., 100) of iteration is complete\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import euclidean as euclidean_dist, cosine as cosine_dist\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Redefined distance computation functions\n",
    "def calc_euclidean_dist(point_a, point_b):\n",
    "    return euclidean_dist(point_a, point_b)\n",
    "\n",
    "def calc_cosine_similarity(point_a, point_b):\n",
    "    return 1 - np.dot(point_a, point_b) / (np.linalg.norm(point_a) * np.linalg.norm(point_b))\n",
    "\n",
    "def calc_generalized_jaccard_similarity(point_a, point_b):\n",
    "    min_sum = np.minimum(point_a, point_b).sum()\n",
    "    max_sum = np.maximum(point_a, point_b).sum()\n",
    "    return 1 - min_sum / max_sum if max_sum != 0 else 0\n",
    "\n",
    "# Modified K-means algorithm\n",
    "def perform_kmeans(data_points, num_clusters, distance_function, max_iterations=100):\n",
    "    random_indices = np.random.choice(data_points.shape[0], num_clusters, replace=False)\n",
    "    cluster_centers = data_points[random_indices]\n",
    "    \n",
    "    for iter in range(max_iterations):\n",
    "        assigned_clusters = np.array([np.argmin([distance_function(dp, center) for center in cluster_centers]) for dp in data_points])\n",
    "        updated_centers = np.array([data_points[assigned_clusters == idx].mean(axis=0) for idx in range(num_clusters)])\n",
    "        \n",
    "        #if np.all(cluster_centers == updated_centers):\n",
    "        #    break\n",
    "        cluster_centers = updated_centers\n",
    "        \n",
    "        _, distances = pairwise_distances_argmin_min(data_points, cluster_centers, metric=distance_function)\n",
    "        sum_squared_error = np.sum(distances ** 2)\n",
    "        #if iter > 0 and sum_squared_error > prev_sse:\n",
    "        #    break\n",
    "        prev_sse = sum_squared_error\n",
    "    \n",
    "    return assigned_clusters, cluster_centers, sum_squared_error, iter\n",
    "\n",
    "# Load dataset\n",
    "# Replace these with your actual file paths or data loading logic\n",
    "data = pd.read_csv('data.csv').values\n",
    "labels = pd.read_csv('label.csv').values.ravel()\n",
    "\n",
    "# Determine number of unique clusters\n",
    "num_clusters = np.unique(labels).size\n",
    "\n",
    "def calculate_accuracy(clusters, true_labels):\n",
    "    cluster_labels = {}\n",
    "    for cluster in set(clusters):\n",
    "        # Find the most frequent label in each cluster\n",
    "        labels_in_cluster = true_labels[clusters == cluster]\n",
    "        most_common_label = np.bincount(labels_in_cluster).argmax()\n",
    "        cluster_labels[cluster] = most_common_label\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    correct_labels_count = sum(cluster_labels[cluster] == true_label for cluster, true_label in zip(clusters, true_labels))\n",
    "    accuracy = correct_labels_count / len(true_labels)\n",
    "    return accuracy\n",
    "\n",
    "# Execute K-means with each distance metric\n",
    "kmeans_results = {}\n",
    "for dist_func, func_name in [(calc_euclidean_dist, 'Euclidean'), (calc_cosine_similarity, 'Cosine'), (calc_generalized_jaccard_similarity, 'Jaccard')]:\n",
    "    clusters, centers, sse, iters = perform_kmeans(data, num_clusters, dist_func)\n",
    "    accuracy = calculate_accuracy(clusters, labels)\n",
    "    kmeans_results[func_name] = {\n",
    "        'Sum of Squared Errors': sse, \n",
    "        'Iterations Completed': iters,\n",
    "        'Accuracy': accuracy\n",
    "    }\n",
    "\n",
    "# Print formatted results with accuracy\n",
    "for method, result in kmeans_results.items():\n",
    "    print(f\"Method: {method}, SSE: {result['Sum of Squared Errors']}, Iterations: {result['Iterations Completed']}, Accuracy: {result['Accuracy']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56962435",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
